{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "substantial-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "indie-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "christian-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "induced-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "sexual-guest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "greek-oakland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "arbitrary-harris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Well, I'll email also, but this may apply to other people, so\n",
      "I'll post also.)\n",
      "\n",
      "\n",
      "\n",
      "Your boss should be the person bring these problems to.  If he/she\n",
      "does not seem to take any action, keep going up higher and higher.\n",
      "Sexual harrassment does not need to be tolerated, and it can be an\n",
      "enormous emotional support to discuss this with someone and know that\n",
      "they are trying to do something about it.  If you feel you can not\n",
      "discuss this with your boss, perhaps your company has a personnel\n",
      "department that can work for you while preserving your privacy.  Most\n",
      "companies will want to deal with this problem because constant anxiety\n",
      "does seriously affect how effectively employees do their jobs.\n",
      "\n",
      "It is unclear from your letter if you have done this or not.  It is\n",
      "not inconceivable that management remains ignorant of employee\n",
      "problems/strife even after eight years (it's a miracle if they do\n",
      "notice).  Perhaps your manager did not bring to the attention of\n",
      "higher ups?  If the company indeed does seem to want to ignore the\n",
      "entire problem, there may be a state agency willing to fight with\n",
      "you.  (check with a lawyer, a women's resource center, etc to find out)\n",
      "\n",
      "You may also want to discuss this with your paster, priest, husband,\n",
      "etc.  That is, someone you know will not be judgemental and that is\n",
      "supportive, comforting, etc.  This will bring a lot of healing.\n",
      "\n",
      "\n",
      "This happens to a lot of people.  Honest.  I believe it may seem\n",
      "to be due to gross insensitivity because of the feelings you are\n",
      "going through.  People in offices tend to be more insensitive while\n",
      "working than they normally are (maybe it's the hustle or stress or...)\n",
      "I've had this happen to me a lot, often because they didn't realize\n",
      "my car was broken, etc.  Then they will come back and wonder why I\n",
      "didn't want to go (this would tend to make me stop being angry at\n",
      "being ignored and make me laugh).  Once, we went off without our\n",
      "boss, who was paying for the lunch :-)\n",
      "\n",
      "\n",
      "Well, if you can't turn to the computer for support, what would\n",
      "we do?  (signs of the computer age :-)\n",
      "\n",
      "In closing, please don't let the hateful actions of a single person\n",
      "harm you.  They are doing it because they are still the playground\n",
      "bully and enjoy seeing the hurt they cause.  And you should not\n",
      "accept the opinions of an imbecile that you are worthless - much\n",
      "wiser people hold you in great esteem.\n"
     ]
    }
   ],
   "source": [
    "print(train_data.data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "virtual-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "electoral-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = CountVectorizer(min_df = 5, binary = True)\n",
    "vectorizer = TfidfVectorizer(min_df = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "boxed-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(train_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "armed-loading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 5903)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "lasting-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "saved-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "blessed-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(test_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "hazardous-emission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1502, 5903)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "clean-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "parallel-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "protected-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fitting-operations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "specified-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = bnb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "reflected-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "requested-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, \\\n",
    "                            precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "published-spelling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "entire-spring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "judicial-weather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 584, 3: 599, 2: 594, 0: 480})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "immune-privacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 983, 3: 438, 0: 406, 2: 430})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "corrected-migration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[316, 124,   3,  37],\n",
       "       [  0, 578,   1,   5],\n",
       "       [  6, 159, 423,   6],\n",
       "       [ 84, 122,   3, 390]], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "distinguished-asbestos",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 396, 0: 319, 3: 398, 1: 389})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "perceived-arrangement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 236, 1: 725, 0: 247, 3: 294})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "empty-mercy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[137, 107,   8,  67],\n",
       "       [  3, 368,   9,   9],\n",
       "       [ 16, 156, 218,   6],\n",
       "       [ 91,  94,   1, 212]], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "amazing-orbit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism      0.778     0.658     0.713       480\n",
      "         comp.graphics      0.588     0.990     0.738       584\n",
      "               sci.med      0.984     0.712     0.826       594\n",
      "soc.religion.christian      0.890     0.651     0.752       599\n",
      "\n",
      "              accuracy                          0.756      2257\n",
      "             macro avg      0.810     0.753     0.757      2257\n",
      "          weighted avg      0.813     0.756     0.760      2257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred, digits=3, target_names=train_data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fresh-timer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism      0.555     0.429     0.484       319\n",
      "         comp.graphics      0.508     0.946     0.661       389\n",
      "               sci.med      0.924     0.551     0.690       396\n",
      "soc.religion.christian      0.721     0.533     0.613       398\n",
      "\n",
      "              accuracy                          0.623      1502\n",
      "             macro avg      0.677     0.615     0.612      1502\n",
      "          weighted avg      0.684     0.623     0.618      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred, digits=3, target_names=train_data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "marked-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "premium-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "renewable-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "every-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = mnb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "affecting-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "confidential-manual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism      0.993     0.631     0.772       480\n",
      "         comp.graphics      0.962     0.945     0.953       584\n",
      "               sci.med      0.982     0.928     0.954       594\n",
      "soc.religion.christian      0.725     0.988     0.836       599\n",
      "\n",
      "              accuracy                          0.885      2257\n",
      "             macro avg      0.915     0.873     0.879      2257\n",
      "          weighted avg      0.911     0.885     0.884      2257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred, digits=3, target_names=train_data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "nearby-supplement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism      0.922     0.260     0.406       319\n",
      "         comp.graphics      0.910     0.882     0.896       389\n",
      "               sci.med      0.909     0.780     0.840       396\n",
      "soc.religion.christian      0.547     0.955     0.695       398\n",
      "\n",
      "              accuracy                          0.742      1502\n",
      "             macro avg      0.822     0.719     0.709      1502\n",
      "          weighted avg      0.816     0.742     0.724      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred, digits=3, target_names=train_data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "outer-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "fifty-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l2', solver='lbfgs', C=10, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "protective-newfoundland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, multi_class='ovr')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "magnetic-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "elder-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "whole-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism      1.000     0.971     0.985       480\n",
      "         comp.graphics      0.937     1.000     0.968       584\n",
      "               sci.med      1.000     0.970     0.985       594\n",
      "soc.religion.christian      0.997     0.985     0.991       599\n",
      "\n",
      "              accuracy                          0.982      2257\n",
      "             macro avg      0.984     0.981     0.982      2257\n",
      "          weighted avg      0.983     0.982     0.982      2257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred, digits=3, target_names=train_data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "moral-hughes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism      0.764     0.630     0.691       319\n",
      "         comp.graphics      0.810     0.918     0.860       389\n",
      "               sci.med      0.850     0.816     0.832       396\n",
      "soc.religion.christian      0.787     0.827     0.806       398\n",
      "\n",
      "              accuracy                          0.806      1502\n",
      "             macro avg      0.803     0.798     0.797      1502\n",
      "          weighted avg      0.805     0.806     0.803      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred, digits=3, target_names=train_data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-horror",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
